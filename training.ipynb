{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import regularizers\n",
    "from sklearn.externals import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(123)\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# import the training data \n",
    "X_total = pd.read_csv('X_musical_features.csv').drop('track_id', axis=1)\n",
    "\n",
    "# import single genres y values\n",
    "y_single_total = pd.read_csv('y_genres_onehot_single.csv').drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# import non-one-hotted y values\n",
    "y_cold_single_total = pd.read_csv('y_genres_single.csv')\n",
    "\n",
    "#import multiple genres y values\n",
    "y_cold_multiple_total = pd.read_csv('y_genres_multiple_cold.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_total, y_single_total, test_size=0.3, shuffle=False, stratify = None\n",
    ")\n",
    "\n",
    "# also split y cold 70/30\n",
    "y_cold_train = y_cold_single_total.head(44559)\n",
    "y_cold_test = y_cold_single_total.tail(y_cold_single_total.shape[0] - 44559)\n",
    "\n",
    "#also split y cold multiple 70/30\n",
    "y_cold_train_multiple = y_cold_multiple_total.head(44559)\n",
    "y_cold_test_multiple = y_cold_multiple_total.tail(y_cold_single_total.shape[0] - 44559)\n",
    "\n",
    "# then do this for \n",
    "# *_train together\n",
    "# *_test together\n",
    "def unison_shuffled_copies(a, b, c, d):\n",
    "    assert len(a) == b.shape[0]\n",
    "    assert a.shape[0] == c.shape[0]\n",
    "    assert a.shape[0] == d.shape[0]\n",
    "    \n",
    "    p = np.random.permutation(len(a))\n",
    "    return a.iloc[p, :], b.iloc[p, :], c.iloc[p, :], d.iloc[p, :]\n",
    "\n",
    "#new variables with shuffled \n",
    "X_train_shuf, y_train_shuf, y_cold_train_shuf, y_cold_train_multiple_shuf = unison_shuffled_copies(X_train, y_train, y_cold_train, y_cold_train_multiple)\n",
    "\n",
    "#also do this for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.save']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_shuf)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "joblib.dump(scaler, \"scaler.save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def create_model(loss):\n",
    "model = keras.models.Sequential()\n",
    "sgd_optimizer = keras.optimizers.SGD(lr=0.001, decay=1e-7, momentum=0.9)\n",
    "\n",
    "# INPUT LAYER\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=518,\n",
    "        input_dim=X_train_scaled.shape[1],\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None),\n",
    "        activation='relu',\n",
    "    )\n",
    ")\n",
    "\n",
    "# HIDDEN LAYER 1\n",
    "#     model.add(\n",
    "#         keras.layers.Dense(\n",
    "#             units=474,\n",
    "#             input_dim=518,\n",
    "#             kernel_initializer='glorot_uniform',\n",
    "#             bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None),\n",
    "#             activation='relu'\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# HIDDEN LAYER 2\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=400,\n",
    "        input_dim=518,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None),\n",
    "        activation='relu',\n",
    "        #kernel_regularizer=regularizers.l2(0.0002),\n",
    "        #activity_regularizer=regularizers.l1(0.0002),\n",
    "    )\n",
    ")\n",
    "model.add(keras.layers.Dropout(0.55))\n",
    "\n",
    "# HIDDEN LAYER 3\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=350,\n",
    "        input_dim=400,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None),\n",
    "        activation='relu',\n",
    "        #kernel_regularizer=regularizers.l2(0.0002),\n",
    "        #activity_regularizer=regularizers.l1(0.0002),\n",
    "    )\n",
    ")\n",
    "model.add(keras.layers.Dropout(0.55))\n",
    "\n",
    "# OUTPUT LAYER\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=y_train.shape[1],\n",
    "        input_dim=350,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None),\n",
    "        activation='softmax'\n",
    "    )\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=sgd_optimizer,\n",
    "    loss='kullback_leibler_divergence',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "    \n",
    "    #return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Things So Far\n",
    "* Batch Size: **60** _(maybe 64 to optimize because of powers of 2)_\n",
    "* Optimizer: **SGD**\n",
    "* Learning Rate: **0.1**\n",
    "    * **HEAVY NOTE** I tried it with 0.1 and it literally exploded (like val_acc went from 3 to 6.5 in one epoch) so I think we don't converge properly with such a high lr. Going back to 0.01 may be optimal but further testing required. \n",
    "    * Final acc with 0.01: around 0.95\n",
    "    * Final acc with 0.1: like 0.3\n",
    "* Momentum: **0.9**\n",
    "* Neurons in Hidden Layer 1: **400**\n",
    "* Neurons in Hidden Layer 2: **350**\n",
    "* Loss equation: **Kullback_leibler_divergence?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TonyX\\Desktop\\WPy-3670\\python-3.6.7.amd64\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] loss=binary_crossentropy ........................................\n",
      "Epoch 1/20\n",
      "29706/29706 [==============================] - 5s 162us/step - loss: 0.0412 - acc: 0.9928\n",
      "Epoch 2/20\n",
      "29706/29706 [==============================] - 4s 150us/step - loss: 0.0364 - acc: 0.9928\n",
      "Epoch 3/20\n",
      "29706/29706 [==============================] - 6s 189us/step - loss: 0.0340 - acc: 0.9927\n",
      "Epoch 4/20\n",
      "29706/29706 [==============================] - 5s 168us/step - loss: 0.0329 - acc: 0.9927\n",
      "Epoch 5/20\n",
      "29706/29706 [==============================] - 5s 156us/step - loss: 0.0322 - acc: 0.9927\n",
      "Epoch 6/20\n",
      "29706/29706 [==============================] - 5s 156us/step - loss: 0.0317 - acc: 0.9927\n",
      "Epoch 7/20\n",
      "29706/29706 [==============================] - 5s 154us/step - loss: 0.0312 - acc: 0.9927\n",
      "Epoch 8/20\n",
      "29706/29706 [==============================] - 4s 150us/step - loss: 0.0309 - acc: 0.9928\n",
      "Epoch 9/20\n",
      "29706/29706 [==============================] - 4s 148us/step - loss: 0.0306 - acc: 0.9927\n",
      "Epoch 10/20\n",
      "29706/29706 [==============================] - 4s 146us/step - loss: 0.0303 - acc: 0.9928\n",
      "Epoch 11/20\n",
      "29706/29706 [==============================] - 4s 150us/step - loss: 0.0301 - acc: 0.9927\n",
      "Epoch 12/20\n",
      "29706/29706 [==============================] - 4s 150us/step - loss: 0.0298 - acc: 0.9928\n",
      "Epoch 13/20\n",
      "29706/29706 [==============================] - 4s 149us/step - loss: 0.0296 - acc: 0.9928\n",
      "Epoch 14/20\n",
      "29706/29706 [==============================] - 4s 150us/step - loss: 0.0294 - acc: 0.9928\n",
      "Epoch 15/20\n",
      "29706/29706 [==============================] - 4s 141us/step - loss: 0.0292 - acc: 0.9928\n",
      "Epoch 16/20\n",
      "29706/29706 [==============================] - 5s 153us/step - loss: 0.0291 - acc: 0.9928\n",
      "Epoch 17/20\n",
      "29706/29706 [==============================] - 5s 154us/step - loss: 0.0289 - acc: 0.9928\n",
      "Epoch 18/20\n",
      "29706/29706 [==============================] - 6s 196us/step - loss: 0.0287 - acc: 0.9928\n",
      "Epoch 19/20\n",
      "29706/29706 [==============================] - 5s 181us/step - loss: 0.0287 - acc: 0.9928\n",
      "Epoch 20/20\n",
      "29706/29706 [==============================] - 5s 161us/step - loss: 0.0285 - acc: 0.9928\n",
      "14853/14853 [==============================] - 1s 65us/step\n",
      "29706/29706 [==============================] - 2s 68us/step\n",
      "[CV]  loss=binary_crossentropy, score=0.9928707456914598, total= 1.6min\n",
      "[CV] loss=binary_crossentropy ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "29706/29706 [==============================] - 6s 194us/step - loss: 0.0409 - acc: 0.9928\n",
      "Epoch 2/20\n",
      "29706/29706 [==============================] - 5s 172us/step - loss: 0.0364 - acc: 0.9928\n",
      "Epoch 3/20\n",
      "29706/29706 [==============================] - 5s 165us/step - loss: 0.0341 - acc: 0.9927\n",
      "Epoch 4/20\n",
      "29706/29706 [==============================] - 7s 228us/step - loss: 0.0331 - acc: 0.9927\n",
      "Epoch 5/20\n",
      "29706/29706 [==============================] - 5s 184us/step - loss: 0.0324 - acc: 0.9927\n",
      "Epoch 6/20\n",
      "29706/29706 [==============================] - 5s 178us/step - loss: 0.0319 - acc: 0.9928\n",
      "Epoch 7/20\n",
      "29706/29706 [==============================] - 5s 162us/step - loss: 0.0315 - acc: 0.9927\n",
      "Epoch 8/20\n",
      "29706/29706 [==============================] - 5s 164us/step - loss: 0.0311 - acc: 0.9928\n",
      "Epoch 9/20\n",
      "29706/29706 [==============================] - 5s 160us/step - loss: 0.0309 - acc: 0.9927\n",
      "Epoch 10/20\n",
      "29706/29706 [==============================] - 5s 161us/step - loss: 0.0306 - acc: 0.9928\n",
      "Epoch 11/20\n",
      "29706/29706 [==============================] - 5s 166us/step - loss: 0.0303 - acc: 0.9928\n",
      "Epoch 12/20\n",
      "29706/29706 [==============================] - 4s 148us/step - loss: 0.0301 - acc: 0.9928\n",
      "Epoch 13/20\n",
      "29706/29706 [==============================] - 4s 145us/step - loss: 0.0299 - acc: 0.9928\n",
      "Epoch 14/20\n",
      "29706/29706 [==============================] - 4s 148us/step - loss: 0.0297 - acc: 0.9928\n",
      "Epoch 15/20\n",
      "29706/29706 [==============================] - 5s 155us/step - loss: 0.0296 - acc: 0.9928\n",
      "Epoch 16/20\n",
      "29706/29706 [==============================] - 4s 150us/step - loss: 0.0293 - acc: 0.9928\n",
      "Epoch 17/20\n",
      "29706/29706 [==============================] - 5s 159us/step - loss: 0.0292 - acc: 0.9928\n",
      "Epoch 18/20\n",
      "29706/29706 [==============================] - 5s 159us/step - loss: 0.0291 - acc: 0.9928\n",
      "Epoch 19/20\n",
      "29706/29706 [==============================] - 5s 152us/step - loss: 0.0289 - acc: 0.9928\n",
      "Epoch 20/20\n",
      "29706/29706 [==============================] - 4s 151us/step - loss: 0.0288 - acc: 0.9928\n",
      "14853/14853 [==============================] - 1s 55us/step\n",
      "29706/29706 [==============================] - 1s 49us/step\n",
      "[CV]  loss=binary_crossentropy, score=0.9928949647685587, total= 1.7min\n",
      "[CV] loss=binary_crossentropy ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "29706/29706 [==============================] - 5s 169us/step - loss: 0.0407 - acc: 0.9928\n",
      "Epoch 2/20\n",
      "29706/29706 [==============================] - 4s 143us/step - loss: 0.0362 - acc: 0.9928\n",
      "Epoch 3/20\n",
      "29706/29706 [==============================] - 5s 176us/step - loss: 0.0341 - acc: 0.9928\n",
      "Epoch 4/20\n",
      "29706/29706 [==============================] - 4s 144us/step - loss: 0.0331 - acc: 0.9928\n",
      "Epoch 5/20\n",
      "29706/29706 [==============================] - 5s 172us/step - loss: 0.0324 - acc: 0.9928\n",
      "Epoch 6/20\n",
      "29706/29706 [==============================] - 5s 178us/step - loss: 0.0319 - acc: 0.9928\n",
      "Epoch 7/20\n",
      "29706/29706 [==============================] - 5s 154us/step - loss: 0.0315 - acc: 0.9928\n",
      "Epoch 8/20\n",
      "29706/29706 [==============================] - 5s 157us/step - loss: 0.0312 - acc: 0.9928\n",
      "Epoch 9/20\n",
      "29706/29706 [==============================] - 5s 157us/step - loss: 0.0308 - acc: 0.9928\n",
      "Epoch 10/20\n",
      "29706/29706 [==============================] - 5s 158us/step - loss: 0.0306 - acc: 0.9928\n",
      "Epoch 11/20\n",
      "29706/29706 [==============================] - 5s 154us/step - loss: 0.0303 - acc: 0.9928\n",
      "Epoch 12/20\n",
      "29706/29706 [==============================] - 5s 153us/step - loss: 0.0301 - acc: 0.9928\n",
      "Epoch 13/20\n",
      "29706/29706 [==============================] - 4s 148us/step - loss: 0.0298 - acc: 0.9928\n",
      "Epoch 14/20\n",
      "29706/29706 [==============================] - 5s 165us/step - loss: 0.0296 - acc: 0.9928\n",
      "Epoch 15/20\n",
      "29706/29706 [==============================] - 5s 153us/step - loss: 0.0295 - acc: 0.9928\n",
      "Epoch 16/20\n",
      "29706/29706 [==============================] - 5s 158us/step - loss: 0.0293 - acc: 0.9928\n",
      "Epoch 17/20\n",
      "29706/29706 [==============================] - 5s 160us/step - loss: 0.0291 - acc: 0.9928\n",
      "Epoch 18/20\n",
      "29706/29706 [==============================] - 5s 165us/step - loss: 0.0290 - acc: 0.9928\n",
      "Epoch 19/20\n",
      "29706/29706 [==============================] - 5s 170us/step - loss: 0.0289 - acc: 0.9928\n",
      "Epoch 20/20\n",
      "29706/29706 [==============================] - 5s 166us/step - loss: 0.0287 - acc: 0.9928\n",
      "14853/14853 [==============================] - 1s 70us/step\n",
      "29706/29706 [==============================] - 2s 55us/step\n",
      "[CV]  loss=binary_crossentropy, score=0.9928843083746351, total= 1.6min\n",
      "[CV] loss=kullback_leibler_divergence ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  5.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "29706/29706 [==============================] - 5s 176us/step - loss: 3.0024 - acc: 0.2450\n",
      "Epoch 2/20\n",
      "29706/29706 [==============================] - 5s 163us/step - loss: 2.6049 - acc: 0.3070\n",
      "Epoch 3/20\n",
      "29706/29706 [==============================] - 5s 167us/step - loss: 2.4526 - acc: 0.3329\n",
      "Epoch 4/20\n",
      "29706/29706 [==============================] - 5s 158us/step - loss: 2.3410 - acc: 0.3553\n",
      "Epoch 5/20\n",
      "29706/29706 [==============================] - 5s 156us/step - loss: 2.2358 - acc: 0.3773\n",
      "Epoch 6/20\n",
      "29706/29706 [==============================] - 5s 154us/step - loss: 2.1492 - acc: 0.3928\n",
      "Epoch 7/20\n",
      "29706/29706 [==============================] - 5s 156us/step - loss: 2.0634 - acc: 0.4135\n",
      "Epoch 8/20\n",
      "29706/29706 [==============================] - 5s 160us/step - loss: 1.9792 - acc: 0.4351\n",
      "Epoch 9/20\n",
      "29706/29706 [==============================] - 5s 159us/step - loss: 1.8922 - acc: 0.4553\n",
      "Epoch 10/20\n",
      "29706/29706 [==============================] - 5s 162us/step - loss: 1.8079 - acc: 0.4736\n",
      "Epoch 11/20\n",
      "29706/29706 [==============================] - 5s 160us/step - loss: 1.7328 - acc: 0.4938\n",
      "Epoch 12/20\n",
      "29706/29706 [==============================] - 5s 159us/step - loss: 1.6547 - acc: 0.5126\n",
      "Epoch 13/20\n",
      "29706/29706 [==============================] - 5s 153us/step - loss: 1.5782 - acc: 0.5309\n",
      "Epoch 14/20\n",
      "29706/29706 [==============================] - 4s 150us/step - loss: 1.5044 - acc: 0.5531\n",
      "Epoch 15/20\n",
      "29706/29706 [==============================] - 4s 151us/step - loss: 1.4358 - acc: 0.5665\n",
      "Epoch 16/20\n",
      "29706/29706 [==============================] - 4s 148us/step - loss: 1.3695 - acc: 0.5882\n",
      "Epoch 17/20\n",
      "29706/29706 [==============================] - 4s 147us/step - loss: 1.3112 - acc: 0.6019\n",
      "Epoch 18/20\n",
      "29706/29706 [==============================] - 5s 166us/step - loss: 1.2510 - acc: 0.6187\n",
      "Epoch 19/20\n",
      "29706/29706 [==============================] - 5s 159us/step - loss: 1.1866 - acc: 0.6369\n",
      "Epoch 20/20\n",
      "29706/29706 [==============================] - 5s 163us/step - loss: 1.1510 - acc: 0.6476\n",
      "14853/14853 [==============================] - 1s 72us/step\n",
      "29706/29706 [==============================] - 2s 65us/step\n",
      "[CV]  loss=kullback_leibler_divergence, score=0.3847034269211341, total= 1.6min\n",
      "[CV] loss=kullback_leibler_divergence ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  6.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "29706/29706 [==============================] - 7s 225us/step - loss: 3.0246 - acc: 0.2447\n",
      "Epoch 2/20\n",
      "29706/29706 [==============================] - 5s 180us/step - loss: 2.6309 - acc: 0.3075\n",
      "Epoch 3/20\n",
      "29706/29706 [==============================] - 6s 193us/step - loss: 2.4776 - acc: 0.3307\n",
      "Epoch 4/20\n",
      "29706/29706 [==============================] - 6s 193us/step - loss: 2.3594 - acc: 0.3498\n",
      "Epoch 5/20\n",
      "29706/29706 [==============================] - 5s 172us/step - loss: 2.2510 - acc: 0.3760\n",
      "Epoch 6/20\n",
      "29706/29706 [==============================] - 5s 182us/step - loss: 2.1603 - acc: 0.3897\n",
      "Epoch 7/20\n",
      "29706/29706 [==============================] - 6s 197us/step - loss: 2.0648 - acc: 0.4133 1s - l\n",
      "Epoch 8/20\n",
      "29706/29706 [==============================] - 5s 174us/step - loss: 1.9760 - acc: 0.4369\n",
      "Epoch 9/20\n",
      "29706/29706 [==============================] - 5s 169us/step - loss: 1.8968 - acc: 0.4562\n",
      "Epoch 10/20\n",
      "29706/29706 [==============================] - 5s 160us/step - loss: 1.8086 - acc: 0.4768\n",
      "Epoch 11/20\n",
      "29706/29706 [==============================] - 5s 172us/step - loss: 1.7406 - acc: 0.4934\n",
      "Epoch 12/20\n",
      "29706/29706 [==============================] - 5s 172us/step - loss: 1.6477 - acc: 0.5167\n",
      "Epoch 13/20\n",
      "29706/29706 [==============================] - 5s 172us/step - loss: 1.5831 - acc: 0.5340\n",
      "Epoch 14/20\n",
      "29706/29706 [==============================] - 6s 188us/step - loss: 1.5009 - acc: 0.5557\n",
      "Epoch 15/20\n",
      "29706/29706 [==============================] - 6s 203us/step - loss: 1.4257 - acc: 0.5735\n",
      "Epoch 16/20\n",
      "29706/29706 [==============================] - 7s 229us/step - loss: 1.3675 - acc: 0.5915\n",
      "Epoch 17/20\n",
      "29706/29706 [==============================] - 5s 178us/step - loss: 1.2985 - acc: 0.6074\n",
      "Epoch 18/20\n",
      "29706/29706 [==============================] - 6s 198us/step - loss: 1.2461 - acc: 0.6205\n",
      "Epoch 19/20\n",
      "29706/29706 [==============================] - 7s 225us/step - loss: 1.2166 - acc: 0.6281\n",
      "Epoch 20/20\n",
      "29706/29706 [==============================] - 6s 195us/step - loss: 1.2051 - acc: 0.6358\n",
      "14853/14853 [==============================] - 1s 62us/step\n",
      "29706/29706 [==============================] - 2s 57us/step\n",
      "[CV]  loss=kullback_leibler_divergence, score=0.38382818286670767, total= 1.9min\n",
      "[CV] loss=kullback_leibler_divergence ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  8.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "29706/29706 [==============================] - 7s 227us/step - loss: 3.0156 - acc: 0.2426\n",
      "Epoch 2/20\n",
      "29706/29706 [==============================] - 7s 227us/step - loss: 2.6116 - acc: 0.3101\n",
      "Epoch 3/20\n",
      "29706/29706 [==============================] - 6s 190us/step - loss: 2.4703 - acc: 0.3320\n",
      "Epoch 4/20\n",
      "29706/29706 [==============================] - 6s 212us/step - loss: 2.3456 - acc: 0.3551\n",
      "Epoch 5/20\n",
      "29706/29706 [==============================] - 6s 205us/step - loss: 2.2444 - acc: 0.3752\n",
      "Epoch 6/20\n",
      "29706/29706 [==============================] - 6s 207us/step - loss: 2.1533 - acc: 0.3946\n",
      "Epoch 7/20\n",
      "29706/29706 [==============================] - 5s 161us/step - loss: 2.0632 - acc: 0.4155\n",
      "Epoch 8/20\n",
      "29706/29706 [==============================] - 5s 161us/step - loss: 1.9782 - acc: 0.4329\n",
      "Epoch 9/20\n",
      "29706/29706 [==============================] - 5s 170us/step - loss: 1.9013 - acc: 0.4496\n",
      "Epoch 10/20\n",
      "29706/29706 [==============================] - 5s 165us/step - loss: 1.8092 - acc: 0.4735\n",
      "Epoch 11/20\n",
      "29706/29706 [==============================] - 5s 179us/step - loss: 1.7353 - acc: 0.4931\n",
      "Epoch 12/20\n",
      "29706/29706 [==============================] - 6s 190us/step - loss: 1.6581 - acc: 0.5115\n",
      "Epoch 13/20\n",
      "29706/29706 [==============================] - 8s 271us/step - loss: 1.5874 - acc: 0.5294\n",
      "Epoch 14/20\n",
      "29706/29706 [==============================] - 7s 230us/step - loss: 1.5076 - acc: 0.5510\n",
      "Epoch 15/20\n",
      "29706/29706 [==============================] - 6s 202us/step - loss: 1.4378 - acc: 0.5726\n",
      "Epoch 16/20\n",
      "29706/29706 [==============================] - 7s 238us/step - loss: 1.3781 - acc: 0.5863\n",
      "Epoch 17/20\n",
      "29706/29706 [==============================] - 7s 241us/step - loss: 1.2944 - acc: 0.6098\n",
      "Epoch 18/20\n",
      "29706/29706 [==============================] - 6s 205us/step - loss: 1.2379 - acc: 0.6255 1s\n",
      "Epoch 19/20\n",
      "29706/29706 [==============================] - 6s 209us/step - loss: 1.1758 - acc: 0.6362\n",
      "Epoch 20/20\n",
      "29706/29706 [==============================] - 6s 218us/step - loss: 1.1416 - acc: 0.6519\n",
      "14853/14853 [==============================] - 1s 94us/step\n",
      "29706/29706 [==============================] - 2s 83us/step\n",
      "[CV]  loss=kullback_leibler_divergence, score=0.3781054332468122, total= 2.1min\n",
      "[CV] loss=poisson ....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 10.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "29706/29706 [==============================] - 8s 267us/step - loss: 0.0402 - acc: 0.0957\n",
      "Epoch 2/20\n",
      "29706/29706 [==============================] - 6s 215us/step - loss: 0.0358 - acc: 0.1284\n",
      "Epoch 3/20\n",
      "29706/29706 [==============================] - 6s 217us/step - loss: 0.0339 - acc: 0.1359\n",
      "Epoch 4/20\n",
      "29706/29706 [==============================] - 7s 225us/step - loss: 0.0330 - acc: 0.1405\n",
      "Epoch 5/20\n",
      "29706/29706 [==============================] - 7s 229us/step - loss: 0.0324 - acc: 0.1537\n",
      "Epoch 6/20\n",
      "29706/29706 [==============================] - 6s 198us/step - loss: 0.0319 - acc: 0.1633\n",
      "Epoch 7/20\n",
      "29706/29706 [==============================] - 6s 206us/step - loss: 0.0316 - acc: 0.1720\n",
      "Epoch 8/20\n",
      "29706/29706 [==============================] - 7s 220us/step - loss: 0.0312 - acc: 0.1792\n",
      "Epoch 9/20\n",
      "29706/29706 [==============================] - 6s 198us/step - loss: 0.0309 - acc: 0.1828\n",
      "Epoch 10/20\n",
      "29706/29706 [==============================] - 6s 216us/step - loss: 0.0307 - acc: 0.1905 1s\n",
      "Epoch 11/20\n",
      "29706/29706 [==============================] - 6s 197us/step - loss: 0.0305 - acc: 0.1963\n",
      "Epoch 12/20\n",
      "29706/29706 [==============================] - 7s 219us/step - loss: 0.0303 - acc: 0.2054\n",
      "Epoch 13/20\n",
      "29706/29706 [==============================] - 7s 237us/step - loss: 0.0301 - acc: 0.2073\n",
      "Epoch 14/20\n",
      "29706/29706 [==============================] - 6s 210us/step - loss: 0.0300 - acc: 0.2122 0s - loss: 0.0300 - acc: \n",
      "Epoch 15/20\n",
      "29706/29706 [==============================] - 6s 219us/step - loss: 0.0298 - acc: 0.2172\n",
      "Epoch 16/20\n",
      "29706/29706 [==============================] - 6s 200us/step - loss: 0.0296 - acc: 0.2227\n",
      "Epoch 17/20\n",
      "29706/29706 [==============================] - 6s 204us/step - loss: 0.0295 - acc: 0.2261\n",
      "Epoch 18/20\n",
      "29706/29706 [==============================] - 7s 221us/step - loss: 0.0293 - acc: 0.2302\n",
      "Epoch 19/20\n",
      "29706/29706 [==============================] - 5s 181us/step - loss: 0.0293 - acc: 0.2295\n",
      "Epoch 20/20\n",
      "29706/29706 [==============================] - 5s 173us/step - loss: 0.0291 - acc: 0.2345\n",
      "14853/14853 [==============================] - 1s 68us/step\n",
      "29706/29706 [==============================] - 2s 64us/step\n",
      "[CV] .......... loss=poisson, score=0.26593954083751464, total= 2.2min\n",
      "[CV] loss=poisson ....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 12.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "29706/29706 [==============================] - 5s 184us/step - loss: 0.0413 - acc: 0.0643\n",
      "Epoch 2/20\n",
      "29706/29706 [==============================] - 7s 225us/step - loss: 0.0370 - acc: 0.1317\n",
      "Epoch 3/20\n",
      "29706/29706 [==============================] - 6s 202us/step - loss: 0.0348 - acc: 0.1416\n",
      "Epoch 4/20\n",
      "29706/29706 [==============================] - 6s 218us/step - loss: 0.0336 - acc: 0.1474\n",
      "Epoch 5/20\n",
      "29706/29706 [==============================] - 6s 216us/step - loss: 0.0329 - acc: 0.1533\n",
      "Epoch 6/20\n",
      "29706/29706 [==============================] - 7s 226us/step - loss: 0.0323 - acc: 0.1642 2s - loss: 0\n",
      "Epoch 7/20\n",
      "29706/29706 [==============================] - 6s 214us/step - loss: 0.0319 - acc: 0.1687\n",
      "Epoch 8/20\n",
      "29706/29706 [==============================] - 6s 197us/step - loss: 0.0316 - acc: 0.1757\n",
      "Epoch 9/20\n",
      "29706/29706 [==============================] - 6s 203us/step - loss: 0.0313 - acc: 0.1810\n",
      "Epoch 10/20\n",
      "29706/29706 [==============================] - 6s 215us/step - loss: 0.0310 - acc: 0.1883\n",
      "Epoch 11/20\n",
      "29706/29706 [==============================] - 7s 222us/step - loss: 0.0308 - acc: 0.1933\n",
      "Epoch 12/20\n",
      "29706/29706 [==============================] - 7s 222us/step - loss: 0.0306 - acc: 0.1981\n",
      "Epoch 13/20\n",
      "29706/29706 [==============================] - 6s 211us/step - loss: 0.0305 - acc: 0.2059\n",
      "Epoch 14/20\n",
      "29706/29706 [==============================] - 7s 225us/step - loss: 0.0302 - acc: 0.2110\n",
      "Epoch 15/20\n",
      "29706/29706 [==============================] - 7s 243us/step - loss: 0.0301 - acc: 0.2129\n",
      "Epoch 16/20\n",
      "29706/29706 [==============================] - 6s 217us/step - loss: 0.0299 - acc: 0.2181\n",
      "Epoch 17/20\n",
      "29706/29706 [==============================] - 6s 201us/step - loss: 0.0298 - acc: 0.2208\n",
      "Epoch 18/20\n",
      "29706/29706 [==============================] - 6s 205us/step - loss: 0.0296 - acc: 0.2230\n",
      "Epoch 19/20\n",
      "29706/29706 [==============================] - 7s 221us/step - loss: 0.0295 - acc: 0.2269\n",
      "Epoch 20/20\n",
      "29706/29706 [==============================] - 8s 263us/step - loss: 0.0294 - acc: 0.2290\n",
      "14853/14853 [==============================] - 2s 123us/step\n",
      "29706/29706 [==============================] - 2s 61us/step\n",
      "[CV] ........... loss=poisson, score=0.2633138086591868, total= 2.2min\n",
      "[CV] loss=poisson ....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 15.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "29706/29706 [==============================] - 5s 183us/step - loss: 0.0401 - acc: 0.0817\n",
      "Epoch 2/20\n",
      "29706/29706 [==============================] - 6s 196us/step - loss: 0.0360 - acc: 0.1316\n",
      "Epoch 3/20\n",
      "29706/29706 [==============================] - 7s 250us/step - loss: 0.0340 - acc: 0.1424\n",
      "Epoch 4/20\n",
      "29706/29706 [==============================] - 5s 163us/step - loss: 0.0331 - acc: 0.1497\n",
      "Epoch 5/20\n",
      "29706/29706 [==============================] - 4s 149us/step - loss: 0.0324 - acc: 0.1570\n",
      "Epoch 6/20\n",
      "29706/29706 [==============================] - 4s 149us/step - loss: 0.0320 - acc: 0.1664\n",
      "Epoch 7/20\n",
      "29706/29706 [==============================] - 5s 170us/step - loss: 0.0316 - acc: 0.1707\n",
      "Epoch 8/20\n",
      "29706/29706 [==============================] - 4s 147us/step - loss: 0.0312 - acc: 0.1817\n",
      "Epoch 9/20\n",
      "29706/29706 [==============================] - 5s 169us/step - loss: 0.0310 - acc: 0.1879\n",
      "Epoch 10/20\n",
      "29706/29706 [==============================] - 5s 155us/step - loss: 0.0308 - acc: 0.1905\n",
      "Epoch 11/20\n",
      "29706/29706 [==============================] - 5s 167us/step - loss: 0.0305 - acc: 0.1957\n",
      "Epoch 12/20\n",
      "29706/29706 [==============================] - 5s 152us/step - loss: 0.0303 - acc: 0.2026\n",
      "Epoch 13/20\n",
      "29706/29706 [==============================] - 5s 160us/step - loss: 0.0302 - acc: 0.2059\n",
      "Epoch 14/20\n",
      "29706/29706 [==============================] - 5s 159us/step - loss: 0.0300 - acc: 0.2157\n",
      "Epoch 15/20\n",
      "29706/29706 [==============================] - 5s 156us/step - loss: 0.0298 - acc: 0.2155\n",
      "Epoch 16/20\n",
      "29706/29706 [==============================] - 5s 181us/step - loss: 0.0297 - acc: 0.2206\n",
      "Epoch 17/20\n",
      "29706/29706 [==============================] - 5s 156us/step - loss: 0.0295 - acc: 0.2203\n",
      "Epoch 18/20\n",
      "29706/29706 [==============================] - 5s 180us/step - loss: 0.0294 - acc: 0.2258\n",
      "Epoch 19/20\n",
      "29706/29706 [==============================] - 5s 171us/step - loss: 0.0293 - acc: 0.2315\n",
      "Epoch 20/20\n",
      "29706/29706 [==============================] - 5s 152us/step - loss: 0.0292 - acc: 0.2335\n",
      "14853/14853 [==============================] - 1s 76us/step\n",
      "29706/29706 [==============================] - 2s 62us/step\n",
      "[CV] .......... loss=poisson, score=0.26324648219214974, total= 1.7min\n",
      "[CV] loss=cosine_proximity ...........................................\n",
      "Epoch 1/20\n",
      "29706/29706 [==============================] - 6s 194us/step - loss: -0.2522 - acc: 0.1950\n",
      "Epoch 2/20\n",
      "29706/29706 [==============================] - 5s 166us/step - loss: -0.3354 - acc: 0.2667\n",
      "Epoch 3/20\n",
      "29706/29706 [==============================] - 5s 157us/step - loss: -0.3683 - acc: 0.3024\n",
      "Epoch 4/20\n",
      "29706/29706 [==============================] - 5s 159us/step - loss: -0.3884 - acc: 0.3263\n",
      "Epoch 5/20\n",
      "29706/29706 [==============================] - 5s 154us/step - loss: -0.4043 - acc: 0.3455\n",
      "Epoch 6/20\n",
      "29706/29706 [==============================] - 5s 162us/step - loss: -0.4176 - acc: 0.3610\n",
      "Epoch 7/20\n",
      "29706/29706 [==============================] - 5s 174us/step - loss: -0.4309 - acc: 0.3774\n",
      "Epoch 8/20\n",
      "29706/29706 [==============================] - 5s 162us/step - loss: -0.4423 - acc: 0.3904\n",
      "Epoch 9/20\n",
      "29706/29706 [==============================] - 5s 162us/step - loss: -0.4560 - acc: 0.4101\n",
      "Epoch 10/20\n",
      "29706/29706 [==============================] - 5s 182us/step - loss: -0.4650 - acc: 0.4203\n",
      "Epoch 11/20\n",
      "29706/29706 [==============================] - 6s 201us/step - loss: -0.4774 - acc: 0.4358\n",
      "Epoch 12/20\n",
      "29706/29706 [==============================] - 5s 184us/step - loss: -0.4882 - acc: 0.4478\n",
      "Epoch 13/20\n",
      "29706/29706 [==============================] - 5s 163us/step - loss: -0.4995 - acc: 0.4637\n",
      "Epoch 14/20\n",
      "29706/29706 [==============================] - 5s 155us/step - loss: -0.5092 - acc: 0.4736\n",
      "Epoch 15/20\n",
      "29706/29706 [==============================] - 5s 174us/step - loss: -0.5190 - acc: 0.4859\n",
      "Epoch 16/20\n",
      "29706/29706 [==============================] - 5s 168us/step - loss: -0.5296 - acc: 0.4971\n",
      "Epoch 17/20\n",
      "29706/29706 [==============================] - 5s 162us/step - loss: -0.5399 - acc: 0.5115\n",
      "Epoch 18/20\n",
      "29706/29706 [==============================] - 5s 160us/step - loss: -0.5487 - acc: 0.5198\n",
      "Epoch 19/20\n",
      "29706/29706 [==============================] - 5s 161us/step - loss: -0.5566 - acc: 0.5281\n",
      "Epoch 20/20\n",
      "29706/29706 [==============================] - 5s 158us/step - loss: -0.5665 - acc: 0.5415\n",
      "14853/14853 [==============================] - 1s 70us/step\n",
      "29706/29706 [==============================] - 2s 56us/step\n",
      "[CV] .. loss=cosine_proximity, score=0.3519154379626745, total= 1.7min\n",
      "[CV] loss=cosine_proximity ...........................................\n",
      "Epoch 1/20\n",
      "29706/29706 [==============================] - 6s 187us/step - loss: -0.2582 - acc: 0.1907\n",
      "Epoch 2/20\n",
      "29706/29706 [==============================] - 5s 170us/step - loss: -0.3304 - acc: 0.2651\n",
      "Epoch 3/20\n",
      "29706/29706 [==============================] - 5s 161us/step - loss: -0.3531 - acc: 0.2902\n",
      "Epoch 4/20\n",
      "29706/29706 [==============================] - 5s 168us/step - loss: -0.3716 - acc: 0.3095\n",
      "Epoch 5/20\n",
      "29706/29706 [==============================] - 5s 158us/step - loss: -0.3929 - acc: 0.3375\n",
      "Epoch 6/20\n",
      "29706/29706 [==============================] - 5s 157us/step - loss: -0.4075 - acc: 0.3506\n",
      "Epoch 7/20\n",
      "29706/29706 [==============================] - 5s 156us/step - loss: -0.4210 - acc: 0.3684\n",
      "Epoch 8/20\n",
      "29706/29706 [==============================] - 5s 164us/step - loss: -0.4350 - acc: 0.3864\n",
      "Epoch 9/20\n",
      "29706/29706 [==============================] - 5s 158us/step - loss: -0.4455 - acc: 0.3995\n",
      "Epoch 10/20\n",
      "29706/29706 [==============================] - 5s 162us/step - loss: -0.4571 - acc: 0.4125\n",
      "Epoch 11/20\n",
      "29706/29706 [==============================] - 5s 177us/step - loss: -0.4679 - acc: 0.4273\n",
      "Epoch 12/20\n",
      "29706/29706 [==============================] - 5s 170us/step - loss: -0.4776 - acc: 0.4396\n",
      "Epoch 13/20\n",
      "29706/29706 [==============================] - 5s 166us/step - loss: -0.4896 - acc: 0.4545\n",
      "Epoch 14/20\n",
      "29706/29706 [==============================] - 5s 164us/step - loss: -0.4989 - acc: 0.4650\n",
      "Epoch 15/20\n",
      "29706/29706 [==============================] - 5s 164us/step - loss: -0.5084 - acc: 0.4765\n",
      "Epoch 16/20\n",
      "29706/29706 [==============================] - 5s 175us/step - loss: -0.5182 - acc: 0.4884\n",
      "Epoch 17/20\n",
      "29706/29706 [==============================] - 5s 177us/step - loss: -0.5281 - acc: 0.4989\n",
      "Epoch 18/20\n",
      "29706/29706 [==============================] - 5s 183us/step - loss: -0.5363 - acc: 0.5099\n",
      "Epoch 19/20\n",
      "29706/29706 [==============================] - 5s 162us/step - loss: -0.5442 - acc: 0.5178\n",
      "Epoch 20/20\n",
      "29706/29706 [==============================] - 5s 152us/step - loss: -0.5529 - acc: 0.5280\n",
      "14853/14853 [==============================] - 1s 68us/step\n",
      "29706/29706 [==============================] - 2s 53us/step\n",
      "[CV] .. loss=cosine_proximity, score=0.3550797818632533, total= 1.7min\n",
      "[CV] loss=cosine_proximity ...........................................\n",
      "Epoch 1/20\n",
      "29706/29706 [==============================] - 6s 190us/step - loss: -0.2616 - acc: 0.1924\n",
      "Epoch 2/20\n",
      "29706/29706 [==============================] - 5s 170us/step - loss: -0.3363 - acc: 0.2692\n",
      "Epoch 3/20\n",
      "29706/29706 [==============================] - 5s 179us/step - loss: -0.3691 - acc: 0.3056\n",
      "Epoch 4/20\n",
      "29706/29706 [==============================] - 5s 168us/step - loss: -0.3871 - acc: 0.3267\n",
      "Epoch 5/20\n",
      "29706/29706 [==============================] - 5s 161us/step - loss: -0.4030 - acc: 0.3463\n",
      "Epoch 6/20\n",
      "29706/29706 [==============================] - 5s 167us/step - loss: -0.4142 - acc: 0.3586\n",
      "Epoch 7/20\n",
      "29706/29706 [==============================] - 5s 165us/step - loss: -0.4279 - acc: 0.3784\n",
      "Epoch 8/20\n",
      "29706/29706 [==============================] - 5s 156us/step - loss: -0.4383 - acc: 0.3887\n",
      "Epoch 9/20\n",
      "29706/29706 [==============================] - 5s 162us/step - loss: -0.4509 - acc: 0.4052\n",
      "Epoch 10/20\n",
      "29706/29706 [==============================] - 5s 160us/step - loss: -0.4618 - acc: 0.4193\n",
      "Epoch 11/20\n",
      "29706/29706 [==============================] - 5s 158us/step - loss: -0.4723 - acc: 0.4313\n",
      "Epoch 12/20\n",
      "29706/29706 [==============================] - 5s 157us/step - loss: -0.4832 - acc: 0.4447\n",
      "Epoch 13/20\n",
      "29706/29706 [==============================] - 5s 156us/step - loss: -0.4947 - acc: 0.4590\n",
      "Epoch 14/20\n",
      "29706/29706 [==============================] - 5s 162us/step - loss: -0.5051 - acc: 0.4737\n",
      "Epoch 15/20\n",
      "29706/29706 [==============================] - 5s 159us/step - loss: -0.5147 - acc: 0.4831\n",
      "Epoch 16/20\n",
      "29706/29706 [==============================] - 5s 162us/step - loss: -0.5225 - acc: 0.4921\n",
      "Epoch 17/20\n",
      "29706/29706 [==============================] - 5s 161us/step - loss: -0.5320 - acc: 0.5047\n",
      "Epoch 18/20\n",
      "29706/29706 [==============================] - 5s 172us/step - loss: -0.5413 - acc: 0.5145\n",
      "Epoch 19/20\n",
      "29706/29706 [==============================] - 5s 160us/step - loss: -0.5511 - acc: 0.5268\n",
      "Epoch 20/20\n",
      "29706/29706 [==============================] - 5s 163us/step - loss: -0.5572 - acc: 0.5319\n",
      "14853/14853 [==============================] - 1s 70us/step\n",
      "29706/29706 [==============================] - 2s 56us/step\n",
      "[CV] .. loss=cosine_proximity, score=0.3622837137288697, total= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 22.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44559/44559 [==============================] - 9s 193us/step - loss: 0.0399 - acc: 0.9928\n",
      "Epoch 2/20\n",
      "44559/44559 [==============================] - 8s 174us/step - loss: 0.0347 - acc: 0.9927\n",
      "Epoch 3/20\n",
      "44559/44559 [==============================] - 8s 173us/step - loss: 0.0330 - acc: 0.9927\n",
      "Epoch 4/20\n",
      "44559/44559 [==============================] - 8s 172us/step - loss: 0.0320 - acc: 0.9927\n",
      "Epoch 5/20\n",
      "44559/44559 [==============================] - 8s 182us/step - loss: 0.0314 - acc: 0.9927\n",
      "Epoch 6/20\n",
      "44559/44559 [==============================] - 8s 179us/step - loss: 0.0308 - acc: 0.9927\n",
      "Epoch 7/20\n",
      "44559/44559 [==============================] - 8s 185us/step - loss: 0.0305 - acc: 0.9928\n",
      "Epoch 8/20\n",
      "44559/44559 [==============================] - 8s 179us/step - loss: 0.0301 - acc: 0.9928\n",
      "Epoch 9/20\n",
      "44559/44559 [==============================] - 8s 173us/step - loss: 0.0298 - acc: 0.9928\n",
      "Epoch 10/20\n",
      "44559/44559 [==============================] - 8s 178us/step - loss: 0.0295 - acc: 0.9928\n",
      "Epoch 11/20\n",
      "44559/44559 [==============================] - 8s 189us/step - loss: 0.0292 - acc: 0.9928\n",
      "Epoch 12/20\n",
      "44559/44559 [==============================] - 8s 188us/step - loss: 0.0290 - acc: 0.9928\n",
      "Epoch 13/20\n",
      "44559/44559 [==============================] - 8s 177us/step - loss: 0.0289 - acc: 0.9928\n",
      "Epoch 14/20\n",
      "44559/44559 [==============================] - 8s 180us/step - loss: 0.0286 - acc: 0.9928\n",
      "Epoch 15/20\n",
      "44559/44559 [==============================] - 8s 171us/step - loss: 0.0284 - acc: 0.9928\n",
      "Epoch 16/20\n",
      "44559/44559 [==============================] - 7s 167us/step - loss: 0.0282 - acc: 0.9928\n",
      "Epoch 17/20\n",
      "44559/44559 [==============================] - 7s 167us/step - loss: 0.0281 - acc: 0.9928\n",
      "Epoch 18/20\n",
      "44559/44559 [==============================] - 8s 184us/step - loss: 0.0280 - acc: 0.9928 0s - loss: 0.0280 - acc: 0.9\n",
      "Epoch 19/20\n",
      "44559/44559 [==============================] - 8s 181us/step - loss: 0.0279 - acc: 0.9929\n",
      "Epoch 20/20\n",
      "44559/44559 [==============================] - 8s 175us/step - loss: 0.0277 - acc: 0.9929\n"
     ]
    }
   ],
   "source": [
    "# model = KerasClassifier(\n",
    "#     build_fn=create_model,\n",
    "#     batch_size=64,\n",
    "#     epochs=20,\n",
    "#     verbose=1)\n",
    "\n",
    "# losses = [  'binary_crossentropy' ,\n",
    "#             'kullback_leibler_divergence' , 'poisson' , 'cosine_proximity']\n",
    "# param_grid = dict(loss=losses)\n",
    "\n",
    "# grid = GridSearchCV(\n",
    "#     estimator=model, \n",
    "#     param_grid=param_grid, \n",
    "#     n_jobs=1,\n",
    "#     verbose=9,\n",
    "# )\n",
    "\n",
    "# #TRY RUNNING THIS WITH X_TRAIN_SCALED AND Y_TRAIN_SHUF, WE MAY BE USING THE UNSHUFFLED TEST DATA FOR THIS\n",
    "# #WHICH IS ONLY 30% OF THE TOTAL DATA AND IT IS UNSHUFFLED\n",
    "# grid_result = grid.fit(X_train_scaled, y_train_shuf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.992883 using {'loss': 'binary_crossentropy'}\n",
      "0.992883 (0.000010) with: {'loss': 'binary_crossentropy'}\n",
      "0.382212 (0.002926) with: {'loss': 'kullback_leibler_divergence'}\n",
      "0.264167 (0.001254) with: {'loss': 'poisson'}\n",
      "0.356426 (0.004339) with: {'loss': 'cosine_proximity'}\n"
     ]
    }
   ],
   "source": [
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher epoch exhibits jumping behavior and failing to converge, consider turning decay higher?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44559 samples, validate on 19097 samples\n",
      "Epoch 1/20\n",
      "44559/44559 [==============================] - 16s 353us/step - loss: 3.6762 - acc: 0.1458 - val_loss: 3.0984 - val_acc: 0.2512\n",
      "Epoch 2/20\n",
      "44559/44559 [==============================] - 14s 304us/step - loss: 3.1680 - acc: 0.2124 - val_loss: 2.9304 - val_acc: 0.2760\n",
      "Epoch 3/20\n",
      "44559/44559 [==============================] - 13s 301us/step - loss: 3.0125 - acc: 0.2409 - val_loss: 2.8365 - val_acc: 0.2834\n",
      "Epoch 4/20\n",
      "44559/44559 [==============================] - 13s 296us/step - loss: 2.9148 - acc: 0.2601 - val_loss: 2.7743 - val_acc: 0.2894\n",
      "Epoch 5/20\n",
      "44559/44559 [==============================] - 13s 288us/step - loss: 2.8408 - acc: 0.2727 - val_loss: 2.7355 - val_acc: 0.2980\n",
      "Epoch 6/20\n",
      "44559/44559 [==============================] - 13s 287us/step - loss: 2.7891 - acc: 0.2812 - val_loss: 2.7077 - val_acc: 0.2979\n",
      "Epoch 7/20\n",
      "44559/44559 [==============================] - 15s 329us/step - loss: 2.7388 - acc: 0.2896 - val_loss: 2.6942 - val_acc: 0.2952\n",
      "Epoch 8/20\n",
      "44559/44559 [==============================] - 14s 309us/step - loss: 2.7054 - acc: 0.2966 - val_loss: 2.6751 - val_acc: 0.2992\n",
      "Epoch 9/20\n",
      "44559/44559 [==============================] - 15s 342us/step - loss: 2.6696 - acc: 0.3009 - val_loss: 2.6635 - val_acc: 0.3012\n",
      "Epoch 10/20\n",
      "44559/44559 [==============================] - 15s 331us/step - loss: 2.6400 - acc: 0.3070 - val_loss: 2.6546 - val_acc: 0.2982\n",
      "Epoch 11/20\n",
      "44559/44559 [==============================] - 15s 338us/step - loss: 2.6088 - acc: 0.3126 - val_loss: 2.6332 - val_acc: 0.3055\n",
      "Epoch 12/20\n",
      "44559/44559 [==============================] - 15s 333us/step - loss: 2.5801 - acc: 0.3165 - val_loss: 2.6284 - val_acc: 0.3034\n",
      "Epoch 13/20\n",
      "44559/44559 [==============================] - 15s 347us/step - loss: 2.5640 - acc: 0.3192 - val_loss: 2.6103 - val_acc: 0.3083\n",
      "Epoch 14/20\n",
      "44559/44559 [==============================] - 15s 345us/step - loss: 2.5381 - acc: 0.3237 - val_loss: 2.6107 - val_acc: 0.3096 - loss: 2.5439 - ac - ETA: 0s - loss: 2.5421 \n",
      "Epoch 15/20\n",
      "44559/44559 [==============================] - 16s 349us/step - loss: 2.5167 - acc: 0.3285 - val_loss: 2.5954 - val_acc: 0.3149\n",
      "Epoch 16/20\n",
      "44559/44559 [==============================] - 15s 345us/step - loss: 2.4953 - acc: 0.3345 - val_loss: 2.5949 - val_acc: 0.3102\n",
      "Epoch 17/20\n",
      "44559/44559 [==============================] - 15s 340us/step - loss: 2.4766 - acc: 0.3353 - val_loss: 2.5955 - val_acc: 0.3120\n",
      "Epoch 18/20\n",
      "44559/44559 [==============================] - 16s 352us/step - loss: 2.4585 - acc: 0.3389 - val_loss: 2.5859 - val_acc: 0.3128\n",
      "Epoch 19/20\n",
      "44559/44559 [==============================] - 16s 353us/step - loss: 2.4438 - acc: 0.3404 - val_loss: 2.5855 - val_acc: 0.3138\n",
      "Epoch 20/20\n",
      "44559/44559 [==============================] - 16s 352us/step - loss: 2.4192 - acc: 0.3466 - val_loss: 2.5870 - val_acc: 0.3094\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(\n",
    "X_train_scaled, y_train_shuf,\n",
    "batch_size=64, epochs=20,\n",
    "verbose=1,\n",
    "validation_data=(X_test_scaled, y_test),\n",
    ")\n",
    "\n",
    "plt.plot(history.history['val_acc'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "# plt.legend(['gn', 'gu', 'ln', 'lu', 'hn', 'hu'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss, val_loss = history.history['loss'] , history.history['val_loss'] \n",
    "\n",
    "#plt.plot(loss, label=\"Loss\")\n",
    "plt.plot(val_loss, label=\"CV Loss\")\n",
    "plt.legend()\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim(bottom=0, top=5.0)\n",
    "plt.title('Figure 1: Loss & Validation Loss as a function of epochs passed')\n",
    "plt.rcParams[\"figure.figsize\"] = [12,12]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38 38 38 38 30 30 38 38 30 15 15 15 10 15 12 15 10 12 15 25 12 25 25 12\n",
      " 12 12  1 15 10 38  5 15 27 15 15 12 10 10 12 10 12 10 15 12 21 25 10 15\n",
      " 15 10]\n",
      "[25 25 25 25 25 25 25 25 25 64 64 64 64 64 64 64 64 64 64 12 12 12 12 12\n",
      " 12 12 43 15 15 15 15 15 15 15 15 12 12 12 12 12 12 12 43 12 21 12 10 15\n",
      " 21 10]\n",
      "Accuracy on training set: 0.38620705132520927\n",
      "Accuracy on test set: 0.309367963554485\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train_scaled, verbose=0)\n",
    "y_test_pred = model.predict_classes(X_test_scaled, verbose=0)\n",
    "print(y_test_pred[0:50])\n",
    "print(y_cold_test.values.flatten()[0:50])\n",
    "\n",
    "train_acc = np.sum(y_cold_train_shuf.values.flatten() == y_train_pred, axis=0) / 44559\n",
    "test_acc = np.sum(y_cold_test.values.flatten() == y_test_pred, axis=0) / 19097\n",
    "\n",
    "print(f\"Accuracy on training set: {train_acc}\")\n",
    "print(f\"Accuracy on test set: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 0 0]\n",
      "[1 1 1 ... 0 0 0]\n",
      "0.4572140308355214\n",
      "0.39650206838770485\n"
     ]
    }
   ],
   "source": [
    "train_acc_multiple=np.zeros(y_train_pred.shape, dtype = int)\n",
    "test_acc_multiple=np.zeros(y_test_pred.shape, dtype = int)\n",
    "\n",
    "for i in range(len(y_cold_train_multiple_shuf.values)):\n",
    "    answer = y_cold_train_multiple_shuf.values[i]\n",
    "    prediction = y_train_pred[i]\n",
    "    \n",
    "    if prediction in answer:\n",
    "        train_acc_multiple[i] = 1\n",
    "\n",
    "for i in range(len(y_cold_test_multiple.values)):\n",
    "    answer = y_cold_test_multiple.values[i]\n",
    "    prediction = y_test_pred[i]\n",
    "    \n",
    "    if prediction in answer:\n",
    "        test_acc_multiple[i] = 1\n",
    "        \n",
    "print(train_acc_multiple)\n",
    "print(test_acc_multiple)\n",
    "\n",
    "print(np.sum(train_acc_multiple) / y_train_pred.shape[0])\n",
    "print(np.sum(test_acc_multiple) / y_test_pred.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save json file of the model\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
