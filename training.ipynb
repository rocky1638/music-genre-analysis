{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.keras as keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(123)\n",
    "tf.set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the training data \n",
    "X_total = pd.read_csv('X_musical_features.csv').drop('track_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import single genres y values\n",
    "y_single_total = pd.read_csv('y_genres_onehot_single.csv').drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# import non-one-hotted y values\n",
    "y_cold_single_total = pd.read_csv('y_genres_single.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63656, 1)\n",
      "    0\n",
      "0  21\n",
      "1  21\n",
      "2  21\n",
      "3  10\n",
      "4  76\n"
     ]
    }
   ],
   "source": [
    "print(y_cold_single_total.shape)\n",
    "print(y_cold_single_total.iloc[0:5,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63656, 518)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63656, 139)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_single_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_total, y_single_total, test_size=0.3, shuffle=False, stratify = None\n",
    ")\n",
    "\n",
    "# also split y cold 70/30\n",
    "y_cold_train = y_cold_single_total.head(44559)\n",
    "y_cold_test = y_cold_single_total.tail(y_cold_single_total.shape[0] - 44559)\n",
    "\n",
    "# then do this for \n",
    "# *_train together\n",
    "# *_test together\n",
    "def unison_shuffled_copies(a, b, c):\n",
    "    assert len(a) == b.shape[0]\n",
    "    assert a.shape[0] == c.shape[0]\n",
    "    \n",
    "    p = np.random.permutation(len(a))\n",
    "    return a.iloc[p, :], b.iloc[p, :], c.iloc[p, :]\n",
    "\n",
    "#new variables with shuffled \n",
    "X_train_shuf, y_train_shuf, y_cold_train_shuf = unison_shuffled_copies(X_train, y_train, y_cold_train)\n",
    "\n",
    "#also do this for test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing for correctness in shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ('chroma_cens', 'kurtosis', '01')  ('chroma_cens', 'kurtosis', '02')  \\\n",
      "33009                          -0.865313                          -0.436609   \n",
      "11814                           0.046079                          -0.471472   \n",
      "23144                          -0.650234                          -0.715156   \n",
      "25377                           0.189053                           0.324736   \n",
      "22114                           0.369846                           0.532329   \n",
      "\n",
      "       ('chroma_cens', 'kurtosis', '03')  ('chroma_cens', 'kurtosis', '04')  \\\n",
      "33009                          -0.734898                          -0.521307   \n",
      "11814                          -0.561838                          -0.515131   \n",
      "23144                          -0.548415                          -0.533902   \n",
      "25377                           0.355818                          -0.285775   \n",
      "22114                           0.446672                          -0.202046   \n",
      "\n",
      "       ('chroma_cens', 'kurtosis', '05')  \n",
      "33009                          -0.418609  \n",
      "11814                          -0.555745  \n",
      "23144                           1.765920  \n",
      "25377                          -1.129526  \n",
      "22114                          -0.139239  \n",
      "         0    1    2    3    4\n",
      "33009  0.0  0.0  0.0  0.0  0.0\n",
      "11814  0.0  0.0  0.0  0.0  0.0\n",
      "23144  0.0  0.0  0.0  0.0  0.0\n",
      "25377  0.0  0.0  0.0  0.0  0.0\n",
      "22114  0.0  0.0  0.0  0.0  0.0\n",
      "         0\n",
      "33009   15\n",
      "11814   30\n",
      "23144   26\n",
      "25377   10\n",
      "22114  125\n",
      "    0\n",
      "0  21\n",
      "1  21\n",
      "2  21\n",
      "3  10\n",
      "4  76\n",
      "    0\n",
      "0  21\n",
      "1  21\n",
      "2  21\n",
      "3  10\n",
      "4  76\n"
     ]
    }
   ],
   "source": [
    "#Testing values\n",
    "\n",
    "print(X_train_shuf.iloc[0:5,0:5])\n",
    "print(y_train_shuf.iloc[0:5,0:5]) \n",
    "print(y_cold_train_shuf.iloc[0:5,0:5])       #this should be the shuffled value\n",
    "print(y_cold_train.iloc[0:5,0:5])            #this and below should output unshuffled values\n",
    "print(y_cold_single_total.iloc[0:5,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_shuf)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44559, 518)\n",
      "(19097, 518)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=518,\n",
    "        input_dim=X_train_scaled.shape[1],\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=474,\n",
    "        input_dim=518,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=y_train.shape[1],\n",
    "        input_dim=474,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='softmax'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_optimizer = keras.optimizers.SGD(lr=0.001, decay=1e-7, momentum=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40103 samples, validate on 4456 samples\n",
      "Epoch 1/10\n",
      "40103/40103 [==============================] - 4s 94us/step - loss: 3.0048 - val_loss: 2.8062\n",
      "Epoch 2/10\n",
      "40103/40103 [==============================] - 4s 96us/step - loss: 2.7419 - val_loss: 2.6813\n",
      "Epoch 3/10\n",
      "40103/40103 [==============================] - 4s 95us/step - loss: 2.6324 - val_loss: 2.6148\n",
      "Epoch 4/10\n",
      "40103/40103 [==============================] - 4s 101us/step - loss: 2.5609 - val_loss: 2.5697\n",
      "Epoch 5/10\n",
      "40103/40103 [==============================] - 4s 99us/step - loss: 2.5073 - val_loss: 2.5381\n",
      "Epoch 6/10\n",
      "40103/40103 [==============================] - 4s 100us/step - loss: 2.4636 - val_loss: 2.5106\n",
      "Epoch 7/10\n",
      "40103/40103 [==============================] - 4s 96us/step - loss: 2.4275 - val_loss: 2.4898\n",
      "Epoch 8/10\n",
      "40103/40103 [==============================] - 4s 98us/step - loss: 2.3949 - val_loss: 2.4744\n",
      "Epoch 9/10\n",
      "40103/40103 [==============================] - 4s 96us/step - loss: 2.3651 - val_loss: 2.4608\n",
      "Epoch 10/10\n",
      "40103/40103 [==============================] - 4s 96us/step - loss: 2.3380 - val_loss: 2.4468\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_scaled, y_train_shuf,\n",
    "    batch_size=100, epochs=10,\n",
    "    verbose=1,\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict_classes(X_train_scaled, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = np.sum(y_cold_single_total.head(44559).values.flatten() == y_train_pred, axis=0) / 44559"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.08317062770708498\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on training set: {train_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
